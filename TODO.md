# Features
- mysql
	- [ ] shutdown/clean reports with 'truncate table'
	- [ ] test with 5.7
		- [x] build, selects, etc.
		- [ ] fix status variables (now with perfschema?)
	- [ ] improve report data sorting performance, by implementing position() and rnd_pos()
		- [x] position() and rnd_pos() implemeted - this doesn't help at all, 300ms to sort 30k rows is too slow, suspicious
		- [x] fix double snapshot prepare for order by and group by
		- [ ] find a way! explain shows 0 rows and ref = NULL, what the f
	- [ ] windowed tables for active and stats (currently data in them is ever incrementing, fine for automatic tools, not that convenient for humans)
- library
	- [ ] plain-C API
	- [ ] Go server, wrapping it, with http interface and stuff.
- [ ] transient memory stats (aka. memory used by data, that was read from the network, and not yet aggregated)
	- [ ] do it like innodb does with 'show engine status'
	- [ ] udp buffers
	- [ ] udp batches
	- [ ] repacked batches
	- [ ] repacker dictionaries
- docs
	- [x] README (well, should suffice for now)
	- [ ] usage examples, i.e. [something like this](https://github.com/tony2001/pinba_engine/wiki/Usage-examples)
	- [x] guidelines - how to run mysql with jemalloc
	- [x] describe configuration options in readme
	- [ ] document packet fields validation rules and value limits
	- [ ] internals/tuning guide
- tools
	- [x] rtag_* reports support in scripts/convert_mysqldump.php
	- [ ] hv_* reports support in scripts/convert_mysqldump.php
- [ ] {maybe} raw data support
- [ ] {maybe, not strictly needed} calculate real time window for report snapshots (i.e. skip timeslices that have had no data)
	- this is debatable, but useful for correct <something>/sec calculations


# Performance
- [ ] develop benchmark harness + learn to use perf like a pro :)
- [ ] improve dictionaries (multiple choices here)
	- [ ] make dictionary (refcounted or permanent) runtime configureable
	- [ ] split permanent dictionary into it's own api, use for all tag names (never refcount them)
	- [ ] maybe rework dictionaries to be report-based (this virtually eliminates the need for repacker, but will prob require report thread-splitting)
	- [ ] hash strings only once, hack hash table impls to accept hashes instead of strings (impossible with unordered_map?)
	- [x] {medium} per snapshot merger dictionary caches
- [ ] {easy} check dense_hash_map impls
	- [ ] https://github.com/tbricks/sparsehash-c11/commits/development (c++11 move + performance)
	- [ ] check other hashes in general: https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html#which-hash-map-should-i-choose
- [ ] {medium} thread cpu + numa affinity
	- [ ] coordinator (or packet relay for that matter) affinity + priority
	- [ ] repacker affinity + config support
	- [ ] udp collector affinity + config support
	- [ ] doc, how to assign interrupts to cores + numa nodes (links at least)
- [ ] {?} increase udp kernel memory (or at least check for it) on startup
	- kernel udp memory is usually tuned very low
	- so, it's beneficial to increase it to be able to handle high packet+data rates
	- should provide guidelines here (like 1gbps in traffic = ~120mb/sec, should probably reserve at least 60mb for 1/2 second hickups)
- [ ] {easy} flatbuffer (https://google.github.io/flatbuffers/) instead of protobuf?
	- hard to change all clients
	- not really worth it, since pb unpack doesn't seem to take that much cpu
- [ ] {hard} maybe replace nanomsg with something doing less locking / syscalls (thorough meamurements first!)

# Internals
- [x] split pinba_globals_t into 'informational' and 'runtime engine' parts (to simplify testing/experiments)
	- informational: stats, ticker, dictionary, stuff that is just 'cogs'
	- runtime: udp readers, coorinator, the features meat
- [x] split coordinator into 'relay thread' and 'management thread' (management is non-threaded, but needs locking, as it can be used from multiple threads)
- [ ] refactor switches by view type in handler.cpp / view_conf.cpp

# Done

- mysql
	- [x] engine
	- [x] report configs (in comments)
	- [x] table with list of all reports and their data
	- [x] {won't fix, there is no need currently} table listing all open tables and their state
	- [x] raw histogram data tables (current impl just adds a field to existing report table)
	- [x] test with mariadb (those guys install all internal headers, should be simpler to install)
	- [x] debug, why mysql keeps eating memory, when started with no reports and just incoming traffic (valgrind says - everything is freed :( )
		- [x] test with mysql (tested, still leaks, probably my code)
		- [x] test with mariadb (tested, still leaks, probably my code)
		- [x] investigate nanomsg - can silently drop messages even with linger and in req/rep sockets
		- [x] try looking into 5.7 perfschema
		- [x] manually
			- [x] FOUND! nanomsg connect is broken and leaks memory when connecting frequently (until nn_term() anyway)
			see experiments/exp_request_call.cpp
			and https://github.com/nanomsg/nanomsg/issues/575
- [x] logging: levels + configureable format (mysql format from mysql plugin, etc.)
- reports
	- [x] filtering by request min/max time
	- [x] request field/tag based filtering (i.e. take only requests with +browser=chrome)
	- [x] timer tag based filtering (i.e. take only timers with @group=memcached)
- stats
	- [x] mysql table
	- [x] status variables
	- [x] make stats table the same as status variables, or remove it in favor of the former
	- per-report stats
		- [x] rusage
		- [x] packet counts (+ drop counts, filtered out counts, bloom dropped counts)
	- [x] per-thread rusage (repacker seems to be the most cpu-intensive one)
- [x] implement dictionary decay (aka, remove values for dictionary, when they're not used by reports anymore)
	- use case: sending highly unique data to pinba (like 'encrypted urls' in nginx module)
	- [x] timeslices and ref counting for repacker dictionary caches + report 'dictionary timeslice' references
	- [x] {won't fix} propagate data about "fields that are interesting to reports" to repacker threads, and do not add stuff to dictionary if noone is interested (this would break naive raw data implementation, since we'd lose timers/tags that are not used by reports)
- [x] recvmmsg() in udp reader (+ settings)
	- [x] configure support
	- [x] try runtime detection with dlsym (and other symbols like pthread_setname_np)
- [x] {easy, minor} make request and timer tag_name_id-s into flatter arrays for faster searches (cache lines, yo!)
- [x] {medium} sorted arrays for histograms (almost there)
	- [x] timer reports
	- [x] request reports
	- [x] {won't fix, nice to have for experiments} packet reports
- percentiles
	- [x] merge histograms in report snapshots only when percentile calculation is required, do so on the fly
	- [x] {not needed, no perf impact now} calculate all required percentiles in one go (i.e. if we need 95 and 99 - calc them in a single pass)
- [x] {medium, worth it?} simple 'bloom filtering' (aka is this report interested in this packet?)
	- [x] poor man's handmade solution with std::bitset, timer tags only (where it's really needed)
	- try calculating a simple bloom filter (over tag names) for all incoming packets
	- report has it's own bloom, filled with tag names it's interested in
	- compare those 2, if no match - packet doesn't need to be inspected
- [x] {easy, worth it?} per repacker dictionary caches (reduces locking on global dictionary)
- [x] {easy} SO_REUSEPORT for udp threads
	- this reduces kernel lock contention (in my test about halves rusage for udp collector threads)
- [x] try hdr_histogram_c
	- [x] {actually done} rewritten hdr histogram to suit our needs, now using it at 'current tick' aggregation stage
	- [x] {won't do} hack to allow for dynamic resize (currently too expensive to use, as they preallocate on creation)
	- [x] also need to figure out what to do with negative/positive inf in our histograms, and significant digits setting
- [x] pthread_setname_np portable detection at runtime {?}
